from pathlib import Path
from typing import Optional

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from shakers_case_study.rag.pipelines.rag.enums.rag_schema import MyStateSchema
from shakers_case_study.rag.pipelines.rag.run_rag import build_rag_pipeline

router = APIRouter()

# Resolve the absolute path to the YAML configuration file used for the RAG pipeline
BASE_DIR = Path(__file__).resolve().parent
yaml_path = (
    BASE_DIR / ".." / ".." / ".." / ".." / "pipeline_configs" / "standard_pipeline.yaml"
).resolve()

# Initialize the Retrieval-Augmented Generation (RAG) pipeline from the YAML config
pipeline = build_rag_pipeline(yaml_path)


class RAGRequest(BaseModel):
    """
    Request model for the RAG endpoint.

    Attributes:
        question (str): The user's input question to the assistant.
        user_id (str): Identifier for the user making the request.
        thread_id (Optional[str]): Identifier for the conversation thread, defaults to "thread-1".
    """

    question: str
    user_id: str
    thread_id: Optional[str] = "thread-1"


class RAGResponse(BaseModel):
    """
    Response model for the RAG endpoint.

    Attributes:
        assistant_answer (str): The answer generated by the assistant.
    """

    assistant_answer: str


@router.post("/rag", response_model=RAGResponse)
async def run_rag(request: RAGRequest):
    """
    Executes the Retrieval-Augmented Generation (RAG) pipeline with the user's question and context.

    Args:
        request (RAGRequest): The input data containing the question,
        user ID, and optional thread ID.

    Returns:
        RAGResponse: The assistant's generated answer.

    Raises:
        HTTPException 500: If any error occurs during pipeline execution.
    """
    try:
        # Initialize the pipeline state with the user question and starting node
        state = MyStateSchema(
            messages=[{"role": "user", "content": request.question}],
            current_node="malicious_query_detector",
        )

        # Prepare configuration dictionary to pass to the pipeline invocation
        config = {
            "configurable": {
                "user_id": request.user_id,
                "thread_id": request.thread_id,
                "llm": pipeline.llm,
                "db_uri": pipeline.db_uri,
                "embedder": pipeline.embedder,
                "vectorstore": pipeline.vectorstore,
            }
        }

        # Run the RAG pipeline graph with the provided state and config
        result_state = pipeline.run(state, config)

        # Return the last assistant message content as the answer
        return RAGResponse(assistant_answer=result_state["messages"][-1]["content"])

    except Exception as e:
        # Return an HTTP 500 error with the exception details on failure
        raise HTTPException(status_code=500, detail=str(e))
